{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c161ee3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Map the dropdown value to enable_TVDL_strategy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mTT\u001b[49m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     enable_TVDL_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m TT\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TT' is not defined"
     ]
    }
   ],
   "source": [
    "# Map the dropdown value to enable_TVDL_strategy\n",
    "if TT.value == '3':\n",
    "    enable_TVDL_strategy = 1\n",
    "elif TT.value == '1':\n",
    "    enable_TVDL_strategy = 0\n",
    "elif TT.value == '5':\n",
    "    enable_TVDL_strategy = 2\n",
    "def check_strength(training_data, desired_strength):\n",
    "    # Check if any strength in the selected data is >= desired_strength\n",
    "    return any(s['strength'] >= desired_strength for s in training_data)\n",
    "\n",
    "def select_and_format_data(data, desired_strength):\n",
    "    while True:\n",
    "        # Randomly select 4 data points\n",
    "        selected_data = data.sample(n=4)  # Removed random_state for true randomness\n",
    "\n",
    "        # Parse selected data into the required format\n",
    "        training_data_formatted = []\n",
    "        tested_formulations = []\n",
    "        for _, row in selected_data.iterrows():\n",
    "            # Ensure these column names match your DataFrame exactly\n",
    "            powder = row[\"Powderkg\"]\n",
    "            wc = row[\"WC\"]\n",
    "            materials = row[\"Materials\"]\n",
    "            # Extract Fly Ash/GGBFS ratio and curing method from materials as done previously\n",
    "            fa_ggbfs = materials.split(\",\")[0].split(\"-\")[1]\n",
    "            curing_method = materials.split(\",\")[-1].strip()\n",
    "            curing_method = curing_method.replace(\" (Rao et al. 2018)\", \"\").replace(\" (Rao et al.)\", \"\")\n",
    "            strength = row[\"fc_28dGroundTruth\"]\n",
    "            \n",
    "            training_str = f\"A = {powder}, B = {wc}, C = {fa_ggbfs}, D = {curing_method} resulted in a performance of {strength}\"\n",
    "            training_data_formatted.append({'formatted_str': training_str, 'strength': strength})\n",
    "            tested_str = f\"A = {powder}, B = {wc}, C = {fa_ggbfs}, D = {curing_method}\"\n",
    "            tested_formulations.append(tested_str) \n",
    "\n",
    "        # Check if any selected data point's strength >= desired_strength\n",
    "        if not check_strength(training_data_formatted, desired_strength):\n",
    "            # Return both the formatted training data and the tested formulations\n",
    "            return [d['formatted_str'] for d in training_data_formatted], tested_formulations\n",
    "        \n",
    "def find_matching_result(df, suggestion):\n",
    "    if suggestion:\n",
    "        # Create the suggestion string in the same format as the formulation strings\n",
    "        suggestion_str = f'The combination is A = {suggestion[\"A\"]}, B = {suggestion[\"B\"]}, C = {suggestion[\"C\"]}, D = {suggestion[\"D\"]}'\n",
    "        TrainingDat = f'A = {suggestion[\"A\"]}, B = {suggestion[\"B\"]}, C = {suggestion[\"C\"]}, D = {suggestion[\"D\"]}'\n",
    "        \n",
    "        # Look for a match in the DataFrame\n",
    "        match = df[df[\"Formulation\"].str.lower() == suggestion_str.lower()]\n",
    "        \n",
    "        # If a match was found, return the lab result and TrainingDat\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"Strength\"], TrainingDat\n",
    "        \n",
    "        # If no match was found, print the suggestion string for debugging\n",
    "        else:\n",
    "            print(\"No match found for suggestion string: \", suggestion_str)\n",
    "\n",
    "    # If no suggestion provided or no match found, return None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def parse_solution(response):\n",
    "    # Initialize a dictionary to hold the solution\n",
    "    solution = {}\n",
    "\n",
    "    # Function to normalize key names\n",
    "    def normalize_key(key):\n",
    "        # Normalize common variations to a standard form\n",
    "        key_map = {\n",
    "            'powderkg': 'powderkg',\n",
    "            'wc': 'wc',\n",
    "            'materials': 'materials',\n",
    "            'curing': 'curing'\n",
    "        }\n",
    "        for known_key, normalized_key in key_map.items():\n",
    "            if known_key in key.lower().replace(\" \", \"\"):\n",
    "                return normalized_key\n",
    "        return None\n",
    "\n",
    "    # Try to parse the response as JSON\n",
    "    #try:\n",
    "        #json_data = json.loads(response)\n",
    "        #for key, value in json_data.items():\n",
    "            #normalized_key = normalize_key(key)\n",
    "            #if normalized_key:\n",
    "                #solution[normalized_key] = str(value)\n",
    "        #if solution:  # If we successfully extracted data\n",
    "            #return solution\n",
    "    #except json.JSONDecodeError:\n",
    "        # If JSON parsing fails, proceed with regex parsing for the plain text format\n",
    "    keys = ['A', 'B', 'C', 'D']  # Updated to include 'curing'\n",
    "    for key in keys:\n",
    "        if key != 'D':  # For 'curing', we might need a different approach\n",
    "            match = re.search(fr\"{key} = (.*?)(,|$)\", response, re.IGNORECASE)\n",
    "            if match:\n",
    "                value = match.group(1).strip()\n",
    "                solution[key] = value\n",
    "            else:\n",
    "                # If any key wasn't found using regex, return None\n",
    "                return None\n",
    "        else:\n",
    "            # Handle 'curing' specifically based on the presence of keywords\n",
    "            if \"ambient\" in response.lower():\n",
    "                solution[\"D\"] = \"Ambient curing\"\n",
    "            elif \"heat\" in response.lower():\n",
    "                solution[\"D\"] = \"Heat curing\"\n",
    "            else:\n",
    "                # If 'curing' condition is not met, return None\n",
    "                return None\n",
    "    print(solution)\n",
    "    return solution  # Return the solution dictionary if all keys were found with regex\n",
    "\n",
    "    # Return None if neither JSON nor regex parsing succeeded\n",
    "    #return None\n",
    "\n",
    "    \n",
    "def format_response_to_model(lab_result):\n",
    "    \"\"\"\n",
    "    Given a lab result, format a response message to the model.\n",
    "    \"\"\"\n",
    "    return f\"We've achieved a performance of {lab_result['fc_28d_Lab_validation']}. Let's try to do better!\"\n",
    "\n",
    "def parse_materials(materials_str):\n",
    "    match = re.search(r'(\\d+)/(\\d+) FA/GGBFS', materials_str)\n",
    "    if match:\n",
    "        return int(match.group(1)) / (int(match.group(1)) + int(match.group(2)))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def parse_curing(materials_str):\n",
    "    if \"Ambient curing\" in materials_str:\n",
    "        return \"ambient\"\n",
    "    elif \"Heat curing\" in materials_str:\n",
    "        return \"oven\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['FA_GGBFS_ratio'] = df['Materials'].apply(parse_materials)\n",
    "    df['curing'] = df['Materials'].apply(parse_curing)  # Add this line\n",
    "    return df\n",
    "\n",
    "df = load_data('Data/DiscoveryData_Sample.csv')\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "formulation_df = pd.DataFrame(columns=[\"Formulation\", \"Strength\"])\n",
    "\n",
    "# Loop through each row in the original data\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    # Get necessary attributes from row\n",
    "    powder = row[\"Powderkg\"]\n",
    "    wc = row[\"WC\"]\n",
    "    materials = row[\"Materials\"]\n",
    "\n",
    "    # Extract Fly Ash/GGBFS ratio\n",
    "    fa_ggbfs = materials.split(\",\")[0].split(\"-\")[1]\n",
    "    \n",
    "    # Extract curing method\n",
    "    curing_method = materials.split(\",\")[-1].strip()\n",
    "\n",
    "    # Remove unwanted string from curing method\n",
    "    curing_method = curing_method.replace(\" (Rao et al. 2018)\", \"\")\n",
    "    curing_method = curing_method.replace(\" (Rao et al.)\", \"\")\n",
    "    \n",
    "    # Compressive strength\n",
    "    strength = row[\"fc_28dGroundTruth\"]\n",
    "    \n",
    "    # Create formulation string in the same format as the model's output\n",
    "    formulation = f'The combination is A = {powder}, B = {wc}, C = {fa_ggbfs}, D = {curing_method}'\n",
    "    \n",
    "    # Append the formulation and its respective strength to the new DataFrame\n",
    "    new_row = pd.DataFrame({\"Formulation\": [formulation], \"Strength\": [strength]})\n",
    "    formulation_df = pd.concat([formulation_df, new_row], ignore_index=True)\n",
    "\n",
    "def handle_openai_error(exception):\n",
    "    if isinstance(exception, openai.error.RateLimitError):\n",
    "        print(f\"Rate limit error. Will retry after {exception.wait_seconds} seconds.\")\n",
    "        time.sleep(exception.wait_seconds)\n",
    "    elif isinstance(exception, openai.error.InvalidRequestError):\n",
    "        print(f\"Invalid request: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.AuthenticationError):\n",
    "        print(f\"Authentication error: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.ServiceUnavailableError):\n",
    "        print(f\"Service unavailable error. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.APIError):\n",
    "        print(f\"API error: {str(exception)}. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.Timeout):\n",
    "        print(f\"Timeout error: {str(exception)}. Retrying after a longer delay...\")\n",
    "        time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    else:\n",
    "        raise exception\n",
    "        \n",
    "# -> here we also set the API parameters, such as temperature, etc.\n",
    "\n",
    "def call_openai_api(messages,temp, max_retries=5, delay=5):\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model= model_dropdown.value,\n",
    "                temperature=temp,\n",
    "                messages=messages,\n",
    "                max_tokens=500,\n",
    "                n=1\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.OpenAIError as e:\n",
    "            \n",
    "            handle_openai_error(e)\n",
    "            if i < max_retries - 1:  # i is zero indexed\n",
    "                time.sleep(delay)  # wait before trying again\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "# Load the text from the file\n",
    "if  prompt_dropdown.value == 'None 0':\n",
    "    with open('Prompts/prompts_ID_none 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 0':\n",
    "    with open('Prompts/prompts_ID_generic 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 0':\n",
    "    with open('Prompts/prompts_ID_specific 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif  prompt_dropdown.value == 'None 1':\n",
    "    with open('Prompts/prompts_ID_none 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 1':\n",
    "    with open('Prompts/prompts_ID_generic 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 1':\n",
    "    with open('Prompts/prompts_ID_specific 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif  prompt_dropdown.value == 'None 2':\n",
    "    with open('Prompts/prompts_ID_none 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 2':\n",
    "    with open('Prompts/prompts_ID_generic 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 2':\n",
    "    with open('Prompts/prompts_ID_specific 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'zero':\n",
    "    with open('Prompts/prompts_ID_zero.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "  \n",
    "# Store the contents in separate variables\n",
    "#instructions_text = lines[0]\n",
    "DA_role_text = lines[0]\n",
    "context_text = lines[1]\n",
    "iterate_text = lines[2]\n",
    "VM_role_text = lines[3]\n",
    "\n",
    "\n",
    "  \n",
    "# Create the widgets with the loaded text\n",
    "layout = widgets.Layout(width='auto', height='200px')  # adjust the height and width as needed\n",
    "#instructions_prompt = widgets.Textarea(value=instructions_text, description='Instructions:', layout=layout)\n",
    "DA_role_prompt = widgets.Textarea(value=DA_role_text, description='DA Instuctions:', layout=layout)\n",
    "VM_role_prompt = widgets.Textarea(value=VM_role_text, description='VM Instuctions:', layout=layout)\n",
    "context_prompt = widgets.Textarea(value=context_text, description='Design Knowledge:', layout=layout)\n",
    "\n",
    "iterate_prompt = widgets.Textarea(value=iterate_text, description='User:', layout=layout)\n",
    "\n",
    "\n",
    "# Run to display the text box widgets and the save button\n",
    "\n",
    "# Set the 'flex' property for each widget inside main_layout\n",
    "iterate_prompt.layout.flex = '2'       # Adjust the value as needed\n",
    "\n",
    "#Instructions_box = widgets.HBox([instructions_prompt],layout=widgets.Layout(width='100%', height='100px'))\n",
    "Iterate_box = widgets.HBox([iterate_prompt],layout=widgets.Layout(width='100%', height='100px'))\n",
    "\n",
    "title = widgets.HTML(\"<h2>Main Prompts</h2>\")\n",
    "Prompts = widgets.VBox([title ,DA_role_prompt, VM_role_prompt, Iterate_box, context_prompt])\n",
    "\n",
    "temperatures_str = model_temperatures.value\n",
    "# Split the string using commas as a delimiter and convert to float numbers\n",
    "temperatures = [float(t) for t in temperatures_str.split(',')]\n",
    "budget = num_development.value\n",
    "NrOfExper = num_experiments.value\n",
    "\n",
    "desired_strength = formulation_df[\"Strength\"].quantile(targ_quant.value/100)\n",
    "\n",
    "num_entries_above_desired = (formulation_df[\"Strength\"] >= desired_strength).sum()\n",
    "\n",
    "# Print the result\n",
    "\n",
    "print('SUMMARY\\n' +'The design target is to achieve a performance of ',desired_strength, 'within ',num_development.value,' development cycles.\\n' +\n",
    "      'The Experiment is repeated ',num_experiments.value,' times using the ',model_dropdown.value, ' model and the prompt strategy: ',prompt_dropdown.value,'.')\n",
    "print(\"There are \", num_entries_above_desired,' combinations above or equal to desired_strength.')\n",
    "\n",
    "\n",
    "def extract_formulations_from_training_data(training_data):\n",
    "    pattern = re.compile(r'A\\s*=\\s*(\\d+),\\s*B\\s*=\\s*(\\d+\\.\\d+),\\s*C\\s*=\\s*(\\d+\\.\\d+/\\d+\\.\\d+),\\s*D\\s*=\\s*(\\w+)', re.IGNORECASE)\n",
    "    training_formulations = [match.group(0) for data in training_data for match in [pattern.search(data)] if match]\n",
    "    return training_formulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstoneproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
